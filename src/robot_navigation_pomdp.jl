using FileIO
using Images
using LinearAlgebra
using StatsBase

@with_kw mutable struct RobotNavigationMap
    map_name::Symbol = :map
    image # TODO: Figure out what this type is!

    function RobotNavigationMap(map_name::Symbol, filename::String)
        absolutePath = joinpath(@__DIR__, "..", "maps", filename)
        image = load(absolutePath)
        return new(map_name, image)
    end
end

@enum RobotNavigationColor begin
    BLACK
    WHITE
    RED
    GREEN
    BLUE
    YELLOW
    CYAN
    MAGENTA
end

const global OBSERVABLE_COLORS = (BLACK, WHITE, RED, GREEN, BLUE)
const global ALL_COLORS = (BLACK, WHITE, RED, GREEN, BLUE, YELLOW, CYAN, MAGENTA)

@with_kw mutable struct RobotNavigationPose
    x::Real = 0.0
    y::Real = 0.0
    Î¸::Real = 0.0
end

@with_kw mutable struct RobotNavigationState
    pose::RobotNavigationPose = RobotNavigationPose()
    map_name::Symbol = :map
    task_color::RobotNavigationColor = MAGENTA
end

@with_kw mutable struct RobotNavigationAction
    desired_move::Bool = false
    desired_Î¸::Real = 0.0
end

@with_kw mutable struct RobotNavigationObservation
    scans::Vector{NamedTuple{(:depth, :color), Tuple{<:Real, RobotNavigationColor}}} = []
end

const RobotNavigationStates = Vector{RobotNavigationState}
const RobotNavigationActions = Vector{RobotNavigationAction}
const RobotNavigationObservations = Vector{RobotNavigationObservation}

@with_kw mutable struct RobotNavigationPOMDP <: POMDP{RobotNavigationState,
                                                      RobotNavigationAction,
                                                      RobotNavigationObservation}
    maps::Dict{Symbol, RobotNavigationMap} = Dict(:map => RobotNavigationMap(:map, "default.png"))
    size_of_map::Dict{Symbol, NamedTuple{(:width, :height), Tuple{Int, Int}}} = Dict(:map => (width = 10, height = 10))
    meters_per_pixel::Real = 4.0
    num_determinized_orientations::Int = 4 # NOTE: For deterministic only.
    max_tasks_per_map::Int = 1
    task_color_for_map::Dict{Symbol, Vector{RobotNavigationColor}} = Dict(:map => [MAGENTA])
    robot_radius::Real = 0.25
    move_xy_max_speed::Real = 1.0
    move_Î¸_max_speed::Real = float(Ï€) / 4.0
    move_xy_variance::Real = 0.1
    move_Î¸_variance::Real = 0.1
    num_scans::Int = 3
    scan_field_of_view::Real = float(Ï€) / 2.0
    scan_range::Real = 10.0
    scan_depth_variance::Real = 0.1
    scan_color_observation_probability::Real = 0.9
end


function color_to_rgb(color::RobotNavigationColor)
    if color == BLACK
        return (r = 0.0, g = 0.0, b = 0.0)
    elseif color == WHITE
        return (r = 1.0, g = 1.0, b = 1.0)
    elseif color == GREEN
        return (r = 0.0, g = 1.0, b = 0.0)
    elseif color == RED
        return (r = 1.0, g = 0.0, b = 0.0)
    elseif color == BLUE
        return (r = 0.0, g = 0.0, b = 1.0)
    elseif color == YELLOW
        return (r = 1.0, g = 1.0, b = 0.0)
    elseif color == CYAN
        return (r = 0.0, g = 1.0, b = 1.0)
    elseif color == MAGENTA
        return (r = 1.0, g = 0.0, b = 1.0)
    else
        return (r = 0.3333, g = 0.333, b = 0.33)
    end
end


function iscolor(ğ’«::RobotNavigationPOMDP, s::RobotNavigationState, color::RobotNavigationColor)
    image = ğ’«.maps[s.map_name].image
    height = round(Int, size(image, 1))
    width = round(Int, size(image, 2))

    y = floor(Int, s.pose.y / ğ’«.meters_per_pixel) + 1
    x = floor(Int, s.pose.x / ğ’«.meters_per_pixel) + 1

    if y < 1 || y > height || x < 1 || x > width
        if color == BLACK
            return true
        else
            return false
        end
    end

    c = color_to_rgb(color)

    result = (
        c.r == convert(Float64, image[y, x].r)
        && c.g == convert(Float64, image[y, x].g)
        && c.b == convert(Float64, image[y, x].b)
    )

    return result
end


function POMDPs.states(ğ’«::RobotNavigationPOMDP)
    ğ’®::RobotNavigationStates = []
    for (m, map) in ğ’«.maps
        for x in 1:floor(Int, ğ’«.size_of_map[m].width * ğ’«.meters_per_pixel)
            for y in 1:floor(Int, ğ’«.size_of_map[m].height * ğ’«.meters_per_pixel)
                for o in 1:ğ’«.num_determinized_orientations
                    for t in ğ’«.task_color_for_map[m]
                        s = RobotNavigationState(
                            pose = RobotNavigationPose(
                                x = x,
                                y = y,
                                Î¸ = loop_angle(2.0 * Ï€ * (o - 1) / ğ’«.num_determinized_orientations)
                            ),
                            map_name = m,
                            task_color = t,
                        )
                        push!(ğ’®, s)
                    end
                end
            end
        end
    end
    return ğ’®
end


function POMDPs.stateindex(ğ’«::RobotNavigationPOMDP, s::RobotNavigationState)
    # TODO: Make this more efficient later.

    ğ’® = states(ğ’«)
    for (i, sâ€²) in ğ’®
        if sâ€² == s
            return i
        end
    end

    return missing
end


function POMDPs.actions(ğ’«::RobotNavigationPOMDP)
    ğ’œ::RobotNavigationActions = []
    for m in [false, true]
        for o in 1:ğ’«.num_determinized_orientations
            a = RobotNavigationAction(
                desired_move = m,
                desired_Î¸ = loop_angle(2.0 * Ï€ * (o - 1) / ğ’«.num_determinized_orientations),
            )
            push!(ğ’œ, a)
        end
    end
    return ğ’œ
end


function POMDPs.actionindex(ğ’«::RobotNavigationPOMDP, a::RobotNavigationAction)
    # TODO: Make this more efficient later.

    ğ’œ = actions(ğ’«)
    for (i, aâ€²) in ğ’œ
        if aâ€² == a
            return i
        end
    end

    return missing
end


function POMDPs.observations(ğ’«::RobotNavigationPOMDP)
    ğ’ª::RobotNavigationObservations = []
    depth_factors = [[
            0, ğ’«.scan_range
        ] for i in 1:ğ’«.num_scans
    ]

    color_factors = [[
            c for c in OBSERVABLE_COLORS
        ] for i in 1:ğ’«.num_scans
    ]
    for d in permutations_with_replacement(depth_factors)
        for c in permutations_with_replacement(color_factors)
            depth_colors = []
            for i in 1:ğ’«.num_scans
                push!(depth_colors, (
                    depth = d[i],
                    color = c[i]
                ))
            end
            o = RobotNavigationObservation(depth_colors)
            push!(ğ’ª, o)
        end
    end
    return ğ’ª
end


function POMDPs.transition(ğ’«::RobotNavigationPOMDP, s::RobotNavigationState, a::RobotNavigationAction)
    sâ€²â€² = deepcopy(s)
    changed_Î¸ = difference_of_angles(s.pose.Î¸, a.desired_Î¸) > 0.01

    if !a.desired_move && !changed_Î¸
        return Deterministic(sâ€²â€²)
    end

    # The xy noise is in meters and the Î¸ noise is in radians.
    ğ’©xy = Normal(0.0, ğ’«.move_xy_variance)
    ğ’©Î¸ = Normal(
        clamp(
            turn_to_angle(s.pose.Î¸, a.desired_Î¸),
            -ğ’«.move_Î¸_max_speed,
            ğ’«.move_Î¸_max_speed
        ),
        ğ’«.move_Î¸_variance
    )

    move(rng, sâ€²) = begin
        # Distance is in meters, but the for loop is over mainly pixels.
        # Pixels should be bigger jumps, and since we are only detecting
        # obstacles over them, we set the max iterations to be based
        # on a half-pixel width, and allow for the step to be random.
        max_distance = ğ’«.move_xy_max_speed
        max_half_pixel_iterations = 2 * ceil(ğ’«.move_xy_max_speed / ğ’«.meters_per_pixel)

        # NOTE: Always start the robot at its radius to prevent collisions.
        distance = ğ’«.robot_radius
        for i in 0:max_half_pixel_iterations
            if iscolor(ğ’«, sâ€², BLACK) || distance >= max_distance
                break
            end

            # We are stepping at half-pixel lengths. However,
            # if the meters per pixel is large (e.g. tiny image
            # and robot is sub-pixel in size), then the step
            # which is supposed to be in pixels for efficiency
            # can actually be longer than the step in meters.
            # Thus, we ensure for these cases it is bounded.
            step_size_in_meters = min(ğ’«.move_xy_max_speed, 0.5 * ğ’«.meters_per_pixel)

            # We step with some noise (in meters).
            step_size = step_size_in_meters + rand(rng, ğ’©xy)

            sâ€².pose.x += step_size * cos(sâ€².pose.Î¸)
            sâ€².pose.y += step_size * sin(sâ€².pose.Î¸)
            distance += step_size
        end

        return sâ€²
    end
    turn(rng, sâ€²) = begin
        sâ€².pose.Î¸ = loop_angle(sâ€².pose.Î¸ + rand(rng, ğ’©Î¸))
        return sâ€²
    end
    turn_then_move(rng, sâ€²) = begin
        sâ€².pose.Î¸ = loop_angle(sâ€².pose.Î¸ + rand(rng, ğ’©Î¸))
        return move(rng, sâ€²)
    end

    if a.desired_move && !changed_Î¸
        return ImplicitDistribution(rng -> move(rng, sâ€²â€²))
    end

    if !a.desired_move && changed_Î¸
        return ImplicitDistribution(rng -> turn(rng, sâ€²â€²))
    end

    return ImplicitDistribution(rng -> turn_then_move(rng, sâ€²â€²))
end


function POMDPs.observation(ğ’«::RobotNavigationPOMDP, a::RobotNavigationAction, sâ€²::RobotNavigationState)
    ğ’©d = Normal(0.0, ğ’«.scan_depth_variance)
    sâ€²â€² = deepcopy(sâ€²)

    noisy_color(rng, sâ€²â€²â€²) = begin
        if rand(rng) < ğ’«.scan_color_observation_probability
            # These colors are the observable ones. Other colors
            # are not observable and are used for tasks.
            for c in OBSERVABLE_COLORS
                if iscolor(ğ’«, sâ€²â€²â€², c)
                    return c
                end
            end
        end
        return rand(rng, OBSERVABLE_COLORS)
    end

    noisy_depth_color(rng, sâ€²â€²â€²) = begin
        noise = rand(rng, ğ’©d)

        # Depth is in meters, but the for loop is over mainly pixels.
        # Pixels should be bigger jumps, and since we are only detecting
        # obstacles over them, we set the max iterations to be based
        # on a half-pixel width, and allow for the step to be random.
        # NOTE: We use scan range instead of max depth (transition's move).
        max_depth = ğ’«.scan_range
        max_half_pixel_iterations = 2 * ceil(ğ’«.scan_range / ğ’«.meters_per_pixel)

        # NOTE: Always start the robot at its radius to prevent collisions.
        depth = 0.0
        for i in 0:max_half_pixel_iterations
            # We are stepping at half-pixel lengths. However,
            # if the meters per pixel is large (e.g. tiny image
            # and robot is sub-pixel in size), then the step
            # which is supposed to be in pixels for efficiency
            # can actually be longer than the step in meters.
            # Thus, we ensure for these cases it is bounded.
            # NOTE: We use scan range instead of max depth
            # (transition's move).
            step_size_in_meters = min(ğ’«.scan_range, 0.5 * ğ’«.meters_per_pixel)

            # We step with some noise (in meters).
            step_size = step_size_in_meters # + rand(rng, ğ’©d) # TODO TODO TODO TODO TODO ???

            sâ€²â€²â€².pose.x += step_size * cos(sâ€²â€²â€².pose.Î¸)
            sâ€²â€²â€².pose.y += step_size * sin(sâ€²â€²â€².pose.Î¸)
            depth += step_size

            # NOTE: We switch this to the end because we
            # actually want to be inside the wall to get
            # the color. It also checks for any not-white
            # color to return as the color.
            if !iscolor(ğ’«, sâ€²â€²â€², WHITE) || depth >= max_depth
                break
            end
        end

        return (
            depth = depth + noise,
            color = noisy_color(rng, sâ€²â€²â€²)
        )
    end

    ğ’ª(rng) = begin
        scans = []

        Ï•half = ğ’«.scan_field_of_view / 2.0
        if ğ’«.num_scans > 1
            Ï•step = ğ’«.scan_field_of_view / (ğ’«.num_scans - 1)
            for Ï• in -Ï•half:Ï•step:Ï•half
                sâ€²â€²â€² = deepcopy(sâ€²â€²)
                sâ€²â€²â€².pose.Î¸ += loop_angle(Ï•)
                push!(scans, noisy_depth_color(rng, sâ€²â€²â€²))
            end
        else
            sâ€²â€²â€² = deepcopy(sâ€²â€²)
            push!(scans, noisy_depth_color(rng, sâ€²â€²â€²))
        end

        return RobotNavigationObservation(scans)
    end

    return ImplicitDistribution(ğ’ª)
end


function POMDPs.reward(ğ’«::RobotNavigationPOMDP, s::RobotNavigationState, a::RobotNavigationAction)
    if iscolor(ğ’«, s, s.task_color)
        return 0.0
    else
        return -1.0
    end
end


function POMDPs.initialstate(ğ’«::RobotNavigationPOMDP)
    random_initial_pixel(rng, Î¸, map_name, task_color) = begin
        image = ğ’«.maps[map_name].image
        height = round(Int, size(image, 1))
        width = round(Int, size(image, 2))

        initial_pixels = []
        for py in 1:height
            for px in 1:width
                s = RobotNavigationState(
                    RobotNavigationPose(
                        px * ğ’«.meters_per_pixel,
                        py * ğ’«.meters_per_pixel,
                        Î¸
                    ),
                    map_name,
                    task_color
                )
                if iscolor(ğ’«, s, CYAN)
                    push!(initial_pixels, (y = py, x = px))
                end
            end
        end

        return rand(rng, initial_pixels)
    end

    b(rng) = begin
        map_name, map = rand(rng, ğ’«.maps)
        task_color = rand(rng, ğ’«.task_color_for_map[map_name])
        Î¸ = rand(rng) * 2.0 * Ï€

        pixel = random_initial_pixel(rng, Î¸, map_name, task_color)

        x = pixel.x * ğ’«.meters_per_pixel + rand(rng) * ğ’«.meters_per_pixel
        y = pixel.y * ğ’«.meters_per_pixel + rand(rng) * ğ’«.meters_per_pixel

        return RobotNavigationState(
            RobotNavigationPose(x, y, Î¸),
            map_name,
            task_color
        )
    end

    return ImplicitDistribution(b)
end


function POMDPs.discount(ğ’«::RobotNavigationPOMDP)
    return 0.95
end

